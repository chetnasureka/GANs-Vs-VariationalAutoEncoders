{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_gan =pd.read_csv(\"Gan_output.csv\")\n",
    "pd_vae =pd.read_csv(\"VAE_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_gan = pd_gan.sort_values(['label'])\n",
    "pd_vae = pd_vae.sort_values(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset= pd_gan.loc[pd_gan['label'] == 0]\n",
    "train_gan, test_gan = train_test_split(subset, test_size=0.1)\n",
    "for i in range (1, 10):\n",
    "    subset = pd_gan.loc[pd_gan['label'] == i]\n",
    "    train, test = train_test_split(subset, test_size=0.1)\n",
    "    train_gan = pd.concat([train_gan, train])\n",
    "    test_gan = pd.concat([test_gan, test])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset= pd_vae.loc[pd_vae['label'] == 0]\n",
    "train_vae, test_vae = train_test_split(subset, test_size=0.1)\n",
    "for i in range (1, 10):\n",
    "    subset = pd_vae.loc[pd_vae['label'] == i]\n",
    "    train, test = train_test_split(subset, test_size=0.1)\n",
    "    train_vae = pd.concat([train_vae, train])\n",
    "    test_vae = pd.concat([test_vae, test])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/linuxbrew/.linuxbrew/opt/python3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/linuxbrew/.linuxbrew/opt/python3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "/home/linuxbrew/.linuxbrew/opt/python3/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "train_gan = train_gan.sample(frac=1).reset_index(drop=True)\n",
    "x_values = train_gan.drop(['label'], axis=1)\n",
    "x_train_GAN = x_values.as_matrix()\n",
    "y_train_GAN = train_gan['label'].tolist()\n",
    "\n",
    "test_gan = test_gan.sample(frac=1).reset_index(drop=True)\n",
    "x_values = test_gan.drop(['label'], axis=1)\n",
    "x_test_GAN = x_values.as_matrix()\n",
    "y_test_GAN = test_gan['label'].tolist()\n",
    "\n",
    "train_vae = train_vae.sample(frac=1).reset_index(drop=True)\n",
    "x_values = train_vae.drop(['label'], axis=1)\n",
    "x_train_VAE = x_values.as_matrix()\n",
    "y_train_VAE = train_vae['label'].tolist()\n",
    "\n",
    "test_vae = test_vae.sample(frac=1).reset_index(drop=True)\n",
    "x_values = test_vae.drop(['label'], axis=1)\n",
    "x_test_VAE = x_values.as_matrix()\n",
    "y_test_VAE = test_vae['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Pixel1</th>\n",
       "      <th>Pixel2</th>\n",
       "      <th>Pixel3</th>\n",
       "      <th>Pixel4</th>\n",
       "      <th>Pixel5</th>\n",
       "      <th>Pixel6</th>\n",
       "      <th>Pixel7</th>\n",
       "      <th>Pixel8</th>\n",
       "      <th>Pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel775</th>\n",
       "      <th>Pixel776</th>\n",
       "      <th>Pixel777</th>\n",
       "      <th>Pixel778</th>\n",
       "      <th>Pixel779</th>\n",
       "      <th>Pixel780</th>\n",
       "      <th>Pixel781</th>\n",
       "      <th>Pixel782</th>\n",
       "      <th>Pixel783</th>\n",
       "      <th>Pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6.282638e-05</td>\n",
       "      <td>4.842842e-05</td>\n",
       "      <td>4.011890e-05</td>\n",
       "      <td>6.654814e-05</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>1.192217e-03</td>\n",
       "      <td>7.593835e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.807318e-05</td>\n",
       "      <td>5.812119e-05</td>\n",
       "      <td>2.647939e-04</td>\n",
       "      <td>1.763965e-04</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017604</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>1.885523e-04</td>\n",
       "      <td>1.327526e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.942305e-08</td>\n",
       "      <td>4.274524e-08</td>\n",
       "      <td>9.439393e-08</td>\n",
       "      <td>9.534464e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419842</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.443341e-07</td>\n",
       "      <td>3.537910e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4.411118e-05</td>\n",
       "      <td>2.022621e-05</td>\n",
       "      <td>3.839586e-05</td>\n",
       "      <td>5.154927e-05</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.016070e-05</td>\n",
       "      <td>6.078504e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.350680e-07</td>\n",
       "      <td>3.761456e-07</td>\n",
       "      <td>6.453870e-07</td>\n",
       "      <td>4.668091e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511309</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.039209e-06</td>\n",
       "      <td>3.136589e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        Pixel1        Pixel2        Pixel3        Pixel4    Pixel5  \\\n",
       "0      5  6.282638e-05  4.842842e-05  4.011890e-05  6.654814e-05  0.000131   \n",
       "1      0  6.807318e-05  5.812119e-05  2.647939e-04  1.763965e-04  0.000554   \n",
       "2      3  1.942305e-08  4.274524e-08  9.439393e-08  9.534464e-08  0.000002   \n",
       "3      8  4.411118e-05  2.022621e-05  3.839586e-05  5.154927e-05  0.000047   \n",
       "4      4  1.350680e-07  3.761456e-07  6.453870e-07  4.668091e-07  0.000015   \n",
       "\n",
       "     Pixel6    Pixel7    Pixel8    Pixel9      ...       Pixel775  Pixel776  \\\n",
       "0  0.000085  0.000043  0.000143  0.000036      ...       0.000034  0.000041   \n",
       "1  0.001014  0.004057  0.006623  0.020755      ...       0.017604  0.013493   \n",
       "2  0.000011  0.000028  0.000113  0.000309      ...       0.419842  0.097851   \n",
       "3  0.000110  0.000020  0.000088  0.000035      ...       0.000149  0.000149   \n",
       "4  0.000055  0.000080  0.000789  0.001556      ...       0.511309  0.212991   \n",
       "\n",
       "   Pixel777  Pixel778  Pixel779  Pixel780  Pixel781  Pixel782      Pixel783  \\\n",
       "0  0.000052  0.000218  0.000626  0.001325  0.001343  0.002833  1.192217e-03   \n",
       "1  0.026134  0.014441  0.005305  0.001259  0.000342  0.000176  1.885523e-04   \n",
       "2  0.018908  0.003993  0.001765  0.000257  0.000008  0.000001  1.443341e-07   \n",
       "3  0.000059  0.000034  0.000024  0.000021  0.000018  0.000029  4.016070e-05   \n",
       "4  0.086042  0.014807  0.003597  0.000589  0.000040  0.000004  1.039209e-06   \n",
       "\n",
       "       Pixel784  \n",
       "0  7.593835e-05  \n",
       "1  1.327526e-04  \n",
       "2  3.537910e-08  \n",
       "3  6.078504e-05  \n",
       "4  3.136589e-07  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vae.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 32)          4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=3,input_shape=(28,28,1),padding='valid'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(16,kernel_size=3, padding='valid'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3,padding='valid'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_classification(x_train, x_test, y_train, y_test, batch_size, epochs, num_classes):\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28,28, 1)\n",
    "    x_test = x_test.reshape(-1, 28,28, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "    y_test_one_hot = keras.utils.to_categorical(y_test)\n",
    "\n",
    "    x_train,valid_X,train_label,valid_label = train_test_split(x_train, y_train_one_hot,test_size=0.2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "    trained = model.fit(x_train, train_label, batch_size=batch_size, epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "\n",
    "\n",
    "    test_eval = model.predict(x_test)\n",
    "    return test_eval,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/12\n",
      "7200/7200 [==============================] - 3s 478us/step - loss: 1.1206 - acc: 0.6644 - val_loss: 0.3548 - val_acc: 0.8583\n",
      "Epoch 2/12\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.2288 - acc: 0.9107 - val_loss: 0.1835 - val_acc: 0.9233\n",
      "Epoch 3/12\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.1457 - acc: 0.9410 - val_loss: 0.1182 - val_acc: 0.9539\n",
      "Epoch 4/12\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.1009 - acc: 0.9618 - val_loss: 0.0759 - val_acc: 0.9800\n",
      "Epoch 5/12\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.0642 - acc: 0.9815 - val_loss: 0.0353 - val_acc: 0.9939\n",
      "Epoch 6/12\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.0301 - acc: 0.9933 - val_loss: 0.0251 - val_acc: 0.9961\n",
      "Epoch 7/12\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.0256 - acc: 0.9935 - val_loss: 0.0172 - val_acc: 0.9978\n",
      "Epoch 8/12\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.0152 - acc: 0.9958 - val_loss: 0.0110 - val_acc: 0.9983\n",
      "Epoch 9/12\n",
      "7200/7200 [==============================] - 3s 377us/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0127 - val_acc: 0.9978\n",
      "Epoch 10/12\n",
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "Epoch 11/12\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 0.9956\n",
      "Epoch 12/12\n",
      "7200/7200 [==============================] - 3s 381us/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0094 - val_acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs= 12\n",
    "num_classes = 10\n",
    "GAN_predicted, GAN_actual = do_classification(x_train = x_train_GAN, x_test = x_test_GAN, y_train = y_train_GAN, y_test = y_test_GAN, batch_size = batch_size, epochs = epochs, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/50\n",
      "7200/7200 [==============================] - 3s 471us/step - loss: 1.2346 - acc: 0.7065 - val_loss: 0.6989 - val_acc: 0.7567\n",
      "Epoch 2/50\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.7228 - acc: 0.7439 - val_loss: 0.6241 - val_acc: 0.7767\n",
      "Epoch 3/50\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.6633 - acc: 0.7578 - val_loss: 0.6163 - val_acc: 0.7717\n",
      "Epoch 4/50\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.6364 - acc: 0.7650 - val_loss: 0.5844 - val_acc: 0.7833\n",
      "Epoch 5/50\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.6142 - acc: 0.7703 - val_loss: 0.5715 - val_acc: 0.7894\n",
      "Epoch 6/50\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.5972 - acc: 0.7821 - val_loss: 0.6142 - val_acc: 0.7611\n",
      "Epoch 7/50\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.5789 - acc: 0.7869 - val_loss: 0.5326 - val_acc: 0.8072\n",
      "Epoch 8/50\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.5673 - acc: 0.7922 - val_loss: 0.5242 - val_acc: 0.8094\n",
      "Epoch 9/50\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.5572 - acc: 0.7943 - val_loss: 0.5214 - val_acc: 0.8072\n",
      "Epoch 10/50\n",
      "7200/7200 [==============================] - 3s 446us/step - loss: 0.5458 - acc: 0.8010 - val_loss: 0.5091 - val_acc: 0.8167\n",
      "Epoch 11/50\n",
      "7200/7200 [==============================] - 3s 377us/step - loss: 0.5303 - acc: 0.8061 - val_loss: 0.5230 - val_acc: 0.8022\n",
      "Epoch 12/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.5173 - acc: 0.8060 - val_loss: 0.5143 - val_acc: 0.8089\n",
      "Epoch 13/50\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.5099 - acc: 0.8104 - val_loss: 0.4905 - val_acc: 0.8244\n",
      "Epoch 14/50\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.5105 - acc: 0.8083 - val_loss: 0.4861 - val_acc: 0.8217\n",
      "Epoch 15/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.4992 - acc: 0.8111 - val_loss: 0.4799 - val_acc: 0.8217\n",
      "Epoch 16/50\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4889 - acc: 0.8132 - val_loss: 0.4953 - val_acc: 0.8161\n",
      "Epoch 17/50\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.4877 - acc: 0.8183 - val_loss: 0.4752 - val_acc: 0.8256\n",
      "Epoch 18/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4735 - acc: 0.8215 - val_loss: 0.4791 - val_acc: 0.8178\n",
      "Epoch 19/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.4709 - acc: 0.8211 - val_loss: 0.4724 - val_acc: 0.8283\n",
      "Epoch 20/50\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.4647 - acc: 0.8262 - val_loss: 0.4646 - val_acc: 0.8233\n",
      "Epoch 21/50\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4565 - acc: 0.8249 - val_loss: 0.4696 - val_acc: 0.8206\n",
      "Epoch 22/50\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4567 - acc: 0.8310 - val_loss: 0.4525 - val_acc: 0.8344\n",
      "Epoch 23/50\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.4483 - acc: 0.8292 - val_loss: 0.4573 - val_acc: 0.8289\n",
      "Epoch 24/50\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.4464 - acc: 0.8325 - val_loss: 0.4803 - val_acc: 0.8111\n",
      "Epoch 25/50\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.4441 - acc: 0.8301 - val_loss: 0.4559 - val_acc: 0.8289\n",
      "Epoch 26/50\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.4390 - acc: 0.8313 - val_loss: 0.4702 - val_acc: 0.8150\n",
      "Epoch 27/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.4262 - acc: 0.8408 - val_loss: 0.4615 - val_acc: 0.8283\n",
      "Epoch 28/50\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.4218 - acc: 0.8404 - val_loss: 0.4920 - val_acc: 0.8094\n",
      "Epoch 29/50\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4221 - acc: 0.8372 - val_loss: 0.4577 - val_acc: 0.8328\n",
      "Epoch 30/50\n",
      "7200/7200 [==============================] - 3s 376us/step - loss: 0.4194 - acc: 0.8393 - val_loss: 0.4526 - val_acc: 0.8267\n",
      "Epoch 31/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4132 - acc: 0.8431 - val_loss: 0.4599 - val_acc: 0.8189\n",
      "Epoch 32/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4110 - acc: 0.8465 - val_loss: 0.4880 - val_acc: 0.8122\n",
      "Epoch 33/50\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4078 - acc: 0.8460 - val_loss: 0.4583 - val_acc: 0.8283\n",
      "Epoch 34/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4031 - acc: 0.8446 - val_loss: 0.4678 - val_acc: 0.8200\n",
      "Epoch 35/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.4057 - acc: 0.8488 - val_loss: 0.4422 - val_acc: 0.8272\n",
      "Epoch 36/50\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.3960 - acc: 0.8486 - val_loss: 0.4476 - val_acc: 0.8256\n",
      "Epoch 37/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.3885 - acc: 0.8531 - val_loss: 0.4625 - val_acc: 0.8333\n",
      "Epoch 38/50\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.3912 - acc: 0.8503 - val_loss: 0.4637 - val_acc: 0.8200\n",
      "Epoch 39/50\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.3811 - acc: 0.8564 - val_loss: 0.4547 - val_acc: 0.8306\n",
      "Epoch 40/50\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.3824 - acc: 0.8525 - val_loss: 0.4581 - val_acc: 0.8189\n",
      "Epoch 41/50\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.3795 - acc: 0.8557 - val_loss: 0.4419 - val_acc: 0.8311\n",
      "Epoch 42/50\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.3715 - acc: 0.8585 - val_loss: 0.4301 - val_acc: 0.8378\n",
      "Epoch 43/50\n",
      "7200/7200 [==============================] - 3s 384us/step - loss: 0.3735 - acc: 0.8587 - val_loss: 0.4565 - val_acc: 0.8333\n",
      "Epoch 44/50\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.3742 - acc: 0.8572 - val_loss: 0.4544 - val_acc: 0.8278\n",
      "Epoch 45/50\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.3671 - acc: 0.8575 - val_loss: 0.4401 - val_acc: 0.8378\n",
      "Epoch 46/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.3650 - acc: 0.8599 - val_loss: 0.4471 - val_acc: 0.8361\n",
      "Epoch 47/50\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.3546 - acc: 0.8639 - val_loss: 0.4424 - val_acc: 0.8294\n",
      "Epoch 48/50\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.3583 - acc: 0.8593 - val_loss: 0.4402 - val_acc: 0.8344\n",
      "Epoch 49/50\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.3588 - acc: 0.8647 - val_loss: 0.4612 - val_acc: 0.8306\n",
      "Epoch 50/50\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.3491 - acc: 0.8686 - val_loss: 0.4571 - val_acc: 0.8317\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs= 50\n",
    "num_classes = 10\n",
    "VAE_predicted, VAE_actual = do_classification(x_train = x_train_VAE, x_test = x_test_VAE, y_train = y_train_VAE, y_test = y_test_VAE, batch_size = batch_size, epochs = epochs, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_predicted_y = [np.argmax(i) for i in VAE_predicted]\n",
    "GAN_predicted_y = [np.argmax(i) for i in GAN_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GAN Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAN Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GAN Predicted   0    1    2   3    4    5    6    7    8    9\n",
       "GAN Actual                                                   \n",
       "0              99    0    0   1    0    0    0    0    0    0\n",
       "1               0  100    0   0    0    0    0    0    0    0\n",
       "2               0    0  100   0    0    0    0    0    0    0\n",
       "3               0    0    0  99    1    0    0    0    0    0\n",
       "4               0    0    0   0  100    0    0    0    0    0\n",
       "5               0    0    0   0    0  100    0    0    0    0\n",
       "6               0    0    0   0    0    0  100    0    0    0\n",
       "7               0    0    0   0    0    0    0  100    0    0\n",
       "8               0    0    0   0    0    0    0    0  100    0\n",
       "9               0    0    0   0    0    0    0    0    0  100"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.Series(GAN_predicted_y, name='GAN Predicted')\n",
    "y_actu = pd.Series(GAN_actual, name='GAN Actual')\n",
    "df_confusion_GAN = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>VAE Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "VAE Predicted   0   1   2   3   4   5   6   7   8   9\n",
       "VAE Actual                                           \n",
       "0              81   1   5   2   0   0  10   0   1   0\n",
       "1               0  97   2   1   0   0   0   0   0   0\n",
       "2               2   0  83   2   4   0   9   0   0   0\n",
       "3               4   3   3  82   2   1   5   0   0   0\n",
       "4               0   0   9   3  80   0   8   0   0   0\n",
       "5               0   0   0   1   0  86   1   5   1   6\n",
       "6              10   1  19   3   9   0  58   0   0   0\n",
       "7               0   0   0   0   0   1   0  88   0  11\n",
       "8               0   0   1   0   0   1   2   0  96   0\n",
       "9               0   0   0   0   0   4   0   1   0  95"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.Series(VAE_predicted_y, name='VAE Predicted')\n",
    "y_actu = pd.Series(VAE_actual, name='VAE Actual')\n",
    "df_confusion_VAE = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
